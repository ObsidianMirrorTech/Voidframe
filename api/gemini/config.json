{
  "generation_parameters": {
    "model": {
      "ui_label": "Model:",
      "ui_tooltip": "Select the AI model for this API.",
      "value_type": "str",
      "widget_type": "dropdown",
      "options": [
        "gemini-2.0-flash",
        "gemini-2.0-flash-lite",
        "gemini-2.0-pro-exp-02-05",
        "gemini-2.0-flash-thinking-exp-01-21",
        "gemini-1.5-flash",
        "gemini-1.5-flash-8b",
        "gemini-1.5-pro"
      ],
      "default": "gemini-1.5-flash-8b"
    },
    "temperature": {
      "ui_label": "Temperature:",
      "ui_tooltip": "Controls randomness. Lower values are more deterministic.",
      "value_type": "float",
      "widget_type": "spinner",
      "default": 1.0,
      "range": [
        0.0,
        2.0
      ],
      "step": 0.1
    },
    "top_p": {
      "ui_label": "Top-p:",
      "ui_tooltip": "Nucleus sampling parameter.",
      "value_type": "float",
      "widget_type": "spinner",
      "default": 0.95,
      "range": [
        0.0,
        1.0
      ],
      "step": 0.05
    },
    "top_k": {
      "ui_label": "Top-k:",
      "ui_tooltip": "Top-k sampling parameter.",
      "value_type": "int",
      "widget_type": "spinner",
      "default": 40,
      "range": [
        1,
        100
      ],
      "step": 1
    },
    "max_output_tokens": {
      "ui_label": "Max Tokens:",
      "ui_tooltip": "Maximum number of tokens to generate.",
      "value_type": "int",
      "widget_type": "spinner",
      "default": 1024,
      "range": [
        1,
        8192
      ],
      "step": 64
    }
  },
  "base64_upload_threshold": 1520
}